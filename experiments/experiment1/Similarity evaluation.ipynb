{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n",
      "<Graph uri='http://neo4j.lis.ic.unicamp.br:80/db/data/'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py2neo.database.HTTPTransaction at 0x7f8ba4ce70f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py2neo import Graph\n",
    "\n",
    "### My parameters\n",
    "#graph = Graph(\"http://neo4j.lis.ic.unicamp.br:80/db/data/\", )\n",
    "graph = Graph(host = \"neo4j.lis.ic.unicamp.br\", http_port = 80, bolt = False, secure = False)\n",
    "\n",
    "\n",
    "if(graph):\n",
    "    print (\"Connected\")\n",
    "    print (graph)\n",
    "\n",
    "graph.begin(autocommit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"NormalizedLevenshtein\"# NormalizedLevenshtein, JaroWinkler, Cosine, Jaccard, MetricLCS, OptimalStringAlignment\n",
    "ontology  = 'hfo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n   {\\n      \"label\": \"left ventricular hypertrophy on ecg\",\\n      \"matchedWords\": [],\\n      \"similarity\": 0.5932203389830508,\\n      \"uri\": \"http://bmi.utah.edu/ontologies/hfontology/C0232306\"\\n   },\\n   {\\n      \"label\": \"Left ventricular ejection fraction decreased\",\\n      \"matchedWords\": [],\\n      \"similarity\": 0.5084745762711864,\\n      \"uri\": \"http://bmi.utah.edu/ontologies/hfontology/C1096403\"\\n   },\\n   {\\n      \"label\": \"Left Ventricular Hypertrophy\",\\n      \"matchedWords\": [],\\n      \"similarity\": 0.47457627118644063,\\n      \"uri\": \"http://bmi.utah.edu/ontologies/hfontology/C0149721\"\\n   }\\n]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json  \n",
    "\n",
    "def findEntities(text, n):\n",
    "    payload = { 'text': text, 'n': n, 'ontology':ontology, 'algorithm':algorithm } \n",
    "#    r = requests.post('http://ontomatch.lis.ic.unicamp.br/api/rest/resources', data=json.dumps(payload))\n",
    "    r = requests.post('http://10.1.1.198:8080/ontomatch/rest/resources', data=json.dumps(payload))\n",
    "    \n",
    "    \n",
    "#     restReturn = r.text.replace('callback(', '')\n",
    "#     restReturn = restReturn.replace('})', '}')\n",
    "    returnJson = json.loads(r.text)  \n",
    "    return returnJson\n",
    "\n",
    "\n",
    "json.dumps(findEntities(\"Left ventricular hypertrophy on admission electrocardiogram\", 3), indent=3, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Features Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountFeatures: 39\n",
      "CountHits    : 365\n",
      "%            : 935.8974358974359\n"
     ]
    }
   ],
   "source": [
    "from py2neo import Node, Relationship, NodeSelector\n",
    "selector = NodeSelector(graph)\n",
    "\n",
    "floorLimiar   = 0.35\n",
    "ceilingLimiar = 1\n",
    "result = selector.select(\"ClinicalFeature\")\n",
    "nodelist=list(result)\n",
    "\n",
    "# print(nodelist)\n",
    "\n",
    "countFeatures=0\n",
    "countHits=0\n",
    "\n",
    "with open('out.txt', 'w') as f:\n",
    "\n",
    "    for node in nodelist:\n",
    "        countFeatures += 1\n",
    "        print(\"---------------\\n\\nClinical Feature: {0}\".format(node['label']), file=f)\n",
    "        similarEntities = findEntities(node['label'], 10)\n",
    "        for entity in similarEntities:\n",
    "            if(entity['similarity'] >= floorLimiar and entity['similarity'] <= ceilingLimiar):\n",
    "                #print(\"{0}\".format(entity['label']), file=f)\n",
    "                print(\"{1} (similarity of {0}) [uri {2}]\".format(entity['similarity'], entity['label'], entity['uri'] ), file=f)\n",
    "                countHits += 1\n",
    "        print(file=f)\n",
    "\n",
    "    \n",
    "f.close() \n",
    "\n",
    "print(\"CountFeatures: {0}\".format(countFeatures))\n",
    "print(\"CountHits    : {0}\".format(countHits))\n",
    "print(\"%            : {0}\".format((countHits/countFeatures)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating CSV for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from py2neo import Node, Relationship, NodeSelector\n",
    "import numpy as np\n",
    "\n",
    "selector = NodeSelector(graph)\n",
    "\n",
    "result = selector.select(\"ClinicalFeature\")\n",
    "nodelist=list(result)\n",
    "\n",
    "ceilingLimiar = 1\n",
    "\n",
    "intervalResult = []\n",
    "compiledResult = []\n",
    "\n",
    "# intervals = [0.9, 0.95]\n",
    "# intervals = [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "intervals = [0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "\n",
    "#algorithms = [\"Cosine\", \"NormalizedLevenshtein\", \"Jaccard\", \"JaroWinkler\"]\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    for floorLimiar in intervals:\n",
    "        print(str(algorithm)+\"_\"+str(floorLimiar))\n",
    "        countFeatures=0\n",
    "        countHits=0\n",
    "        intervalResult = []\n",
    "        intervalResult.append(str(algorithm)+\"_\"+str(floorLimiar))\n",
    "\n",
    "        for node in nodelist:\n",
    "            countFeatures += 1\n",
    "            countHits = 0\n",
    "\n",
    "            similarEntities = findEntities(node['label'], 100)\n",
    "\n",
    "            for entity in similarEntities:\n",
    "                if(entity['similarity'] >= floorLimiar and entity['similarity'] <= ceilingLimiar):\n",
    "                    countHits += 1\n",
    "\n",
    "            intervalResult.append(countHits)\n",
    "            \n",
    "            \n",
    "        npIntervalResult = np.array(intervalResult[2:]).astype(np.float) #https://docs.scipy.org/doc/numpy/reference/routines.statistics.html\n",
    "        intervalResult.append(np.amin(npIntervalResult)) #min max average median std var\n",
    "        intervalResult.append(np.amax(npIntervalResult))\n",
    "        intervalResult.append(np.average(npIntervalResult))\n",
    "        intervalResult.append(np.median(npIntervalResult))\n",
    "        intervalResult.append(np.std(npIntervalResult))\n",
    "        intervalResult.append(np.var(npIntervalResult))\n",
    "        \n",
    "        compiledResult.append(intervalResult)\n",
    "\n",
    "    \n",
    "    \n",
    "import csv\n",
    "with open('output/compilation.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(compiledResult)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
